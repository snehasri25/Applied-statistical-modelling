---
title: "USA Wines Analysis"
author: "Sneha Srivastava"
date: "5/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r load_packages, include=FALSE}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(imputeTS)
library(GGally)
library(Boruta)
library(DAAG)
library(DMwR)
```

## Load Data

```{r load_data, echo=FALSE}
wine_full <- read.csv("winemag-data-130k-v2.csv")
head(wine_full)
```
```{r}
str(wine_full)
```

## Filter data

```{r filter_data, include=FALSE}
us_wines <-  wine_full%>%
  filter(country == 'US')
```

## derive new features
```{r}
us_wines<-us_wines %>% 
  mutate(year = as.numeric(str_extract(title, "\\d{4}")))
str(us_wines$year)
```


```{r}
us_wines$wordcount <- sapply(gregexpr("\\S+", us_wines$description), length)

summary(us_wines$wordcount)
```

## removing unnecessary columns

```{r remove_unnecessary_features, include=FALSE}
us_wines1<- within(us_wines, rm("X","country","taster_name","taster_twitter_handle","description","title","designation"))
```

## missing data imputation

```{r impute_data, echo=FALSE}
cat('Rows and Columns -> ')
dim(us_wines1)
cat('\n Rows without null values -> ', sum(complete.cases(us_wines1)))
cat('\n Total null values -> ' , sum(is.na(us_wines1)))
list_na <- colnames(us_wines1)[apply(us_wines1, 2, anyNA)]
cat('\n Columns with null values -> ')
list_na

nulls <- sapply(us_wines1, function(x) sum(is.na(x)))
#cat('null count for each column -> ')
nulls
cat('Using imputeTS to fill NA values with 0 ... ')

mean_fill <- us_wines1%>%
                na_mean()
cat('Missing values after filling with mean -> ', sum(is.na(mean_fill)))
us_wines1 <- mean_fill 
#drop_na(us_wines1)

              
```

```{r}
head(us_wines1)
```
## visualizing the distribution of points

```{r}
ggplot(data = us_wines1, aes(x= points, colour = I('black'), fill = I('#FFC0CB')))+
  geom_histogram(binwidth = 1)+
  labs(x = "Points", y= "Frequency", title = "Distribution of points")
```
##looking at correlation in numerical columns

```{r}
ggplot(data = us_wines1, aes(x=wordcount, y=points))+geom_point()
```
```{r}
cor(us_wines1$points, us_wines1$wordcount)
```

```{r}
ggplot(data = us_wines1, aes(x=price, y=points))+ geom_point()
```
```{r}
cor(us_wines1$points, us_wines1$price)
```


```{r}

cor(us_wines1$points, us_wines1$year)

```

```{r, include=FALSE}
#ggplot(wine_samp) + geom_boxplot(aes(x = reorder(province, points, median), points,fill = reorder(province, points, median)))
#boxplot(points ~ province, data = us_wines1) 
```

## encoding categorical variables

```{r}
encode_ordinal <- function(x, order = unique(x)) {
  x <- as.numeric(factor(x, levels = order, exclude = NULL))
  x
}

#us_wines1$designation<-encode_ordinal(us_wines1[["designation"]])
us_wines1$province <- encode_ordinal(us_wines1[["province"]])
us_wines1$region_1<-encode_ordinal(us_wines1[["region_1"]])
us_wines1$region_2<-encode_ordinal(us_wines1[["region_2"]])
us_wines1$variety<-encode_ordinal(us_wines1[["variety"]])
us_wines1$winery<-encode_ordinal(us_wines1[["winery"]])

```

## sampling datasets
```{r}
ntotal <- nrow(us_wines1)
nsamp <- 1000 ## subset to sample
ind_samp <- sample(1:ntotal, nsamp, replace = FALSE) ## which datapoints to sample
wine_samp <- us_wines1[ind_samp, ] ## which datapoints to sample
wine_samp <- droplevels(wine_samp)
```


## model building
```{r}
model<- lm(points~.,data = wine_samp)
summary(model)
```
from p-values, it is evident which features are important to the model, 
however, validating it with step-wise linear regression.

```{r}
AIC(model)
BIC(model)
```

```{r}
step_AIC_backward <- step(model)
```

```{r}
model2 <- lm(points~wordcount+price+year+winery, data = wine_samp)
summary(model2)
```

```{r}
AIC(model2)
BIC(model2)
```
## checking interaction terms

```{r}
cor(us_wines1$province,us_wines1$region_2)
```


```{r}
cor(us_wines1$province,us_wines1$region_1)
```


```{r}
cor(us_wines1$region_2,us_wines1$region_1)
```

```{r}
cor(us_wines1$wordcount,us_wines1$price)
```

```{r}
model3 <- lm(points~wordcount+price+wordcount*price+province*region_2+region_1*region_2+province*region_1, data = wine_samp)
summary(model3)
```

```{r}
step_AIC_backward1 <- step(model3)
```



```{r}
AIC(model3)
BIC(model3)
```

```{r}
yhat <- predict(model3)
plot(yhat, wine_samp$points)
```

## comparing models for finding a better model
```{r}
anova(model2, model3)
```
## comparing error rates
```{r}
## for model3
DMwR::regr.eval(wine_samp$points, yhat)
```
```{r}
## for model2
yhat1<-predict(model2)
DMwR::regr.eval(wine_samp$points, yhat1)
```
it is significant that from the error rates and anova comaprison that model3 fits slightly better than the model2.
hence using model3 for fitting into entire dataset.

# fitting the model to entire dataset

## Create the training and test data
```{r train_test_split}
trainingRowIndex <- sample(1:nrow(us_wines1), 0.8*nrow(us_wines1))
trainingData <- us_wines1[trainingRowIndex, ]  # model training data
testData  <- us_wines1[-trainingRowIndex, ]   # test data
```


## Fit the model on training data and predict dist on test data
```{r}
# Build the model on training data
lmMod <- lm(points ~ wordcount + price + winery + wordcount * price + province * region_2 + region_1 * region_2 + province * region_1, data = trainingData)  # build the model
pointsPred <- predict(lmMod, testData)  # predict points
```

## review diagnostic measures
```{r}
summary (lmMod) # model summary
```
#as per summary statistics, we can see no high p-value for any of these features


## review diagnostic measures

```{r}
BIC(lmMod)
```


## calculate prediction accuracy
```{r}
actuals_preds <- data.frame(cbind(actuals=testData$points, predicteds=pointsPred))  # make actuals_predicteds dataframe.
correlation_accuracy <- cor(actuals_preds)
correlation_accuracy  #0.6409507
head(actuals_preds)
```
```{r}
# Min-Max Accuracy Calculation
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))  
min_max_accuracy
```

```{r}
plot(pointsPred, testData$points)
```

```{r}
plot(lmMod, which=2)
```

## calculating error rates
```{r}
DMwR::regr.eval(actuals_preds$actuals, actuals_preds$predicteds)
```

```{r}
lmMod1 <- lm(points ~ ., data = trainingData)  # build the model
pointsPred1 <- predict(lmMod1, testData)  # predict points
```


```{r}
plot(lmMod1, which=2)
```


```{r}
BIC(lmMod1)
```

